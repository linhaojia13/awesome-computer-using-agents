# awesome-computer-using-agents

1. [Benchmark](#1-benchmark)
2. [Architecture](#2-architecture)
3. [Data Synth](#3-data-synth)
4. [Reward Model](#4-reward-model)
5. [Training Algorithm](#5-training-algorithm)
6. [Others](#6-others)

## 1. Benchmark
[2508] [OSWorld-Verified](https://xlang.ai/blog/osworld-verified)
> ä¿®æ­£äº†OSWorldçš„ä¸€äº›bugï¼šé—®é¢˜æ¨¡ç³Šã€ç½‘ç«™æ‰“ä¸å¼€ï¼›  
> æŒ‡å‡ºç¤¾åŒºä¸‹ä¸€æ­¥é‡ç‚¹æ˜¯æ„é€ è½¨è¿¹æ•°æ®ã€éªŒè¯å™¨ã€æ›´æœ‰æ•ˆçš„æµ‹è¯„  
> **å¼€æºäº†[ç°æœ‰çš„CUAåœ¨osworldæµ‹è¯•é›†ä¸Šçš„æµ‹è¯„è½¨è¿¹](https://huggingface.co/datasets/xlangai/ubuntu_osworld_verified_trajs)ï¼ŒæŒºæœ‰å‚è€ƒä»·å€¼çš„**

ğŸŒŸ [2506] [OSWorld-Human: Benchmarking the Efficiency of Computer-Use Agents](https://arxiv.org/pdf/2506.16042)
> äººç±»30ç§’å®Œæˆçš„ä»»åŠ¡ï¼ˆå¦‚è°ƒæ•´æ–‡æ¡£è¡Œè·ï¼‰ï¼Œä»£ç†éœ€è€—æ—¶12åˆ†é’Ÿ  
> äººå·¥æ ‡æ³¨OSWorldçš„369ä¸ªçœŸå®ä»»åŠ¡ï¼Œæ„å»ºäººç±»æ“ä½œè½¨è¿¹ï¼Œå‘ç°äººç±»æ“ä½œæ­¥éª¤æ¯”AIä»£ç†å°‘1.4â€“2.7å€  
> æå‡ºæ–°è¯„ä¼°æŒ‡æ ‡ï¼šWESï¼ˆåŠ æƒæ•ˆç‡å¾—åˆ†ï¼‰

[2504] [Computer Agent Arena: Compare & Test AI Agents on Crowdsourced Real-World Computer Use Tasks](https://arena.xlang.ai)
> é’ˆå¯¹CUAçš„ç«æŠ€åœº  
> åšå®¢é‡Œæåˆ°ä¼šé€šè¿‡è¿™ä¸ªarena**æ”¶é›†ç”¨æˆ·åå¥½çš„æŒ‡ä»¤æ•°æ®**ï¼Œå¹¶åœ¨æœªæ¥å¼€æº

[2404] [OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments](https://os-world.github.io)
> 369ä¸ªtaskï¼Œæ¯ä¸ªtaskå¯¹åº”ä¸€ä¸ªè„šæœ¬ä½œä¸ºéªŒè¯å™¨ 

## 2. Architecture
ğŸŒŸ [2508] [CoAct-1: Computer-using Agents with Coding as Actions](https://arxiv.org/pdf/2508.03923)
> ä¸‰å¤§æ™ºèƒ½ä½“åˆ†å·¥â€‹: 1) Orchestratorâ€‹ï¼šä»»åŠ¡åˆ†è§£ä¸å†³ç­–ä¸­æ¢; 2) Programmerâ€‹ï¼šé€šè¿‡ä»£ç ä¸ç³»ç»Ÿç›´æ¥äº¤äº’; 3) GUI Operatorâ€‹ï¼šåŸºäºè§†è§‰æ¨¡å‹æ‰§è¡Œå›¾å½¢æ“ä½œ  
> CoAct-1 vs GTA-1: æˆåŠŸç‡60.76 vs 45.2ï¼Œå¹³å‡æ­¥æ•°10.15 vs 15.22

[2507] [GTA1: GUI Test-time Scaling Agent](https://arxiv.org/pdf/2507.05791)
> planner + judge + grouder  
> plannerè¾“å‡ºå¤šä¸ªcandidate actionï¼Œjudgeä»ä¸­é€‰æ‹©actionï¼Œgrouderè½¬æ¢ä¸ºå¸¦åæ ‡çš„åŠ¨ä½œ
> rlè®­ç»ƒgrouderï¼Œo3ä½œä¸ºplanner+judgeï¼Œosworldèƒ½è¾¾åˆ°45%

[2506][Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://arxiv.org/pdf/2506.21252)
> è¦†ç›–agentä»»åŠ¡å¤ªå¤šæ ·ï¼šç½‘é¡µå¯¼èˆªï¼ˆ417ï¼‰â€‹ã€å…·èº«æ™ºèƒ½ï¼ˆ317ï¼‰ã€æ—…è¡Œè§„åˆ’ï¼ˆ180ï¼‰

ğŸŒŸ [2505][Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis](https://osworld-grounding.github.io)
> ç”¨JEDI-7Bä½œä¸ºgroudingæ¨¡å‹ï¼Œé…åˆGPT-4oè§„åˆ’å™¨ï¼Œåœ¨OSWorldåŸºå‡†ä¸Šçš„æˆåŠŸç‡é«˜è¾¾27%  
> è®­ç»ƒåçš„æ¨¡å‹ï¼ˆå¦‚JEDI-7Bï¼‰â€‹ä¸ç›´æ¥è¾“å‡ºPyAutoGUIä»£ç ï¼Œè€Œæ˜¯é¢„æµ‹ç»“æ„åŒ–åŠ¨ä½œï¼ˆ38é¡µé™„å½•A.4ï¼‰

## 3. Data Synth
### 3.1 Computer
[2508][SEA: Self-Evolution Agent with Step-wise Reward for Computer Use](https://arxiv.org/pdf/2508.04037)
> 7bæ¨¡å‹åœ¨osworldä¸Š30.1ï¼Œæ¯”SE-Agentã€OpenCUAéƒ½æ›´å¼º  
> åŸºäºQWen2.5-VL-72Bè®­ç»ƒå‡ºæ¥çš„step modelå¯ä»¥åˆ¤æ–­actionçš„æ­£ç¡®æ€§ï¼Œä½†æ²¡å±•ç¤ºprompt  
> é€šè¿‡few-shot in-context Learningå»ç”Ÿäº§task

ğŸŒŸ [2508] [SEAgent: Self-Evolving Computer Use Agent with
Autonomous Learning from Experience](https://arxiv.org/pdf/2508.04700)
> Curriculum Generator: ç”Ÿæˆä»»åŠ¡ï¼Œæäº†4245ä¸ªä»»åŠ¡  
> World State Model: ä¹Ÿå°±æ˜¯reward model, ç”¨çš„æ˜¯åŸºäºosworld chomeçš„43ä¸ªtaskå¾—åˆ°çš„860æ¡è½¨è¿¹è®­ç»ƒqwen2.5vl-7bå¾—åˆ°çš„

[2508] [VeriGUI: Verifiable Long-Chain GUI Dataset](https://arxiv.org/pdf/2508.04026)
> VeriGUI æ„å»ºäº†é¦–ä¸ªæ”¯æŒ â€‹é•¿é“¾å¤æ‚ä»»åŠ¡â€‹ï¼ˆæ•°ç™¾æ­¥æ“ä½œï¼‰å’Œ â€‹å­ä»»åŠ¡çº§éªŒè¯â€‹ çš„ GUI æ•°æ®é›†ï¼Œè¦†ç›–æ¡Œé¢å’Œç½‘é¡µç¯å¢ƒã€‚  
> æ•°æ®é›†æŒç»­æ›´æ–°ä¸­ï¼Œç›®å‰åªæœ‰130ç½‘é¡µä»»åŠ¡ï¼Œæ¡Œé¢ä»»åŠ¡å³å°†å‘å¸ƒã€‚  
> æ¡Œé¢éªŒè¯æœºåˆ¶åŸºäºæˆªå›¾å’Œç³»ç»Ÿå±æ€§çš„çŠ¶æ€æ£€æŸ¥ï¼Œç”±äººç±»ä¸“å®¶åœ¨æ ‡æ³¨è¿‡ç¨‹ä¸­å®ç°å‡½æ•°åŒ–

ğŸŒŸ [2508] [OpenCUA: Open Foundations for Computer-Use Agents](https://opencua.xlang.ai)
> 634åæ ‡æ³¨å‘˜é’ˆå¯¹200+åº”ç”¨/ç½‘ç«™ï¼Œæ ‡è®°äº†20k+ä»»åŠ¡çš„è½¨è¿¹  
> å¼€æºäº†æ ‡æ³¨è½¯ä»¶ã€æ•°æ®é›†  
> çº¯sftè®­ç»ƒqwen-vl-32bï¼Œosworldä¸Šåˆ†æ•°34.8

[2506] [AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents](https://arxiv.org/pdf/2506.14205)
> åˆ©ç”¨ä¿¡æ¯ä¸å¯¹ç§°ï¼Œé“¾å¼ç”Ÿæˆå­ä»»åŠ¡â€‹ï¼Œç»„åˆæˆå¤æ‚ä»»åŠ¡ã€‚ä»»åŠ¡ç”ŸæˆæˆåŠŸç‡98%ï¼Œä½†è¯„ä¼°æ—¶SOTAæ¨¡å‹åœ¨Level 6ä»»åŠ¡æˆåŠŸç‡ä»…4%â€‹â€‹  
> å¯æ§ä»»åŠ¡éš¾åº¦: é€šè¿‡å­ä»»åŠ¡æ•°é‡ç²¾ç¡®è°ƒæ§å¤æ‚åº¦ï¼ŒLevel 6ä»»åŠ¡å¹³å‡éœ€40â€“60æ­¥æ“ä½œ  
> â€‹é«˜çœŸå®æ€§ä»»åŠ¡: äººå·¥è¯„ä¼°æ˜¾ç¤ºï¼šä»»åŠ¡å¯è¡Œæ€§87%â€‹ã€å­ä»»åŠ¡è¿è´¯æ€§91%â€‹ã€è§’è‰²ç›¸å…³æ€§94%â€‹  
> æ­ç¤ºLLMä»£ç†ä¸‰å¤§ç¼ºé™·ï¼šé¼ æ ‡ç‚¹å‡»ä¸ç²¾å‡†ï¼ˆ59.1%åŠ¨ä½œï¼‰ã€çŠ¶æ€è·Ÿè¸ªé”™è¯¯ã€é”™è¯¯æ¢å¤èƒ½åŠ›ç¼ºå¤±ï¼ˆç¬¬5.3èŠ‚ï¼‰

[2505] [Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis](https://osworld-grounding.github.io)
> å¤§è§„æ¨¡åˆæˆæ•°æ®é›†JEDIâ€‹ (400w) å’Œç²¾æ ‡çš„åŸºå‡†æµ‹è¯•OSWORLD-Gâ€‹ (564)  
> é€šè¿‡UIæ„é€ groudingæ•°æ®ï¼Œå¹¶å¤„ç†æˆ(å›¾åƒ+æŒ‡ä»¤â†’åŠ¨ä½œ)çš„æ ¼å¼  
> é€šè¿‡æŒ‡ä»¤-æˆªå›¾é”™é…ç”Ÿæˆä¸å¯è¡ŒåŠ¨ä½œæ ·æœ¬ï¼Œå¢å¼ºæ¨¡å‹æ‹’ç»èƒ½åŠ›
> ç”¨JEDI-7Bä½œä¸ºgroudingæ¨¡å‹ï¼Œé…åˆGPT-4oè§„åˆ’å™¨ï¼Œåœ¨OSWorldåŸºå‡†ä¸Šçš„æˆåŠŸç‡é«˜è¾¾27%

[2505][ZeroGUI: Automating Online GUI Learning at Zero Human Cost](https://arxiv.org/pdf/2505.23762)
> å¤ç”¨ç”¨osworldçš„task configï¼Œç”¨LLMç”Ÿæˆæ›´å¤šæŒ‡ä»¤
> task verifierç”¨qwen2.5vl-32b


ğŸŒŸ [2501] [UI-TARS: Pioneering Automated GUI Interaction with Native Agents](https://arxiv.org/pdf/2501.12326)
> groundingæ•°æ®ä»å…¬å¼€æ•°æ®é›†ä¸­æ”¶é›†  
> è½¨è¿¹æ•°æ®ä¸¤éƒ¨åˆ†ï¼š145kç§»åŠ¨ç«¯è½¨è¿¹ï¼Œå›¢é˜Ÿæ ‡æ³¨çš„PCè½¨è¿¹  
> ç”¨VLMç»™è½¨è¿¹æ•°æ®æ‰“ä¸Šæ€ç»´é“¾  
> è¿­ä»£ã€è®­ç»ƒ-æ¨è½¨è¿¹-æ ¡æ­£è½¨è¿¹ã€‘è¿™ä¸ªè¿‡ç¨‹  
> æ ¡æ­£è½¨è¿¹é€šè¿‡å¤šçº§è¿‡æ»¤å®ç°ï¼š1ï¼‰è§„åˆ™å¯å‘å¼ï¼šç§»é™¤æ— æ•ˆåŠ¨ä½œï¼›2ï¼‰VLMè¯„åˆ†ï¼šè¿‡æ»¤ä½åˆ†è½¨è¿¹ï¼›3ï¼‰äººå·¥å®¡æ ¸ï¼šæˆªæ–­é”™è¯¯æ­¥éª¤ï¼Œä¿ç•™æœ‰æ•ˆå‰ç¼€  
> ä¸¤ç§dpoè½¨è¿¹å¯¹ï¼š1ï¼‰å…¬å¼6ï¼Œé”™è¯¯æ­¥éª¤-æ­£ç¡®æ­¥éª¤ï¼›2ï¼‰å…¬å¼7ï¼Œé”™è¯¯å‘ç”Ÿåï¼Œä¸é‡‡å–è¡¥æ•‘-é‡‡å–è¡¥æ•‘

### 3.2 Browser
[2507] [WebShaper: Agentically Data Synthesizing via
Information-Seeking Formalization](https://arxiv.org/pdf/2507.15061)
> formulation-driven data synthï¼Œå°†questionç”¨é›†åˆäº¤å¹¶çš„è¯­è¨€å½¢å¼åŒ–  
> åŸºäºå½¢å¼åŒ–æè¿°ï¼Œåˆ©ç”¨expander agentæ‹“å±•seed question

[2504] [Breaking the Data Barrier â€“ Building GUI Agents Through Task Generalization](https://arxiv.org/pdf/2504.10127)
> é’ˆå¯¹Qwen2-VL-7B-Instructï¼Œæå‡ºåœ¨é¢„è®­ç»ƒå’Œå¾®è°ƒä¹‹é—´å¼•å…¥ä¸€ä¸ªä¸­é—´è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨11ç§ä¸åŒä»»åŠ¡çš„æ•°æ®é›†ï¼ˆåŒ…æ‹¬å¤šæ¨¡æ€å’Œçº¯æ–‡æœ¬ä»»åŠ¡ï¼‰ï¼Œä»¥æå‡æ¨¡å‹çš„åŸºç¡€èƒ½åŠ›ï¼ˆå¦‚æ¨ç†ã€æ„ŸçŸ¥å’Œè§„åˆ’ï¼‰ï¼Œå¯¹GUIä»»åŠ¡å¸®åŠ©å¾ˆå¤§  
> çº¯æ–‡æœ¬æ•°å­¦æ•°æ®ï¼ˆMathInstructï¼‰åœ¨WebArenaåŸºå‡†ä¸Šæå‡5.6%ï¼Œåœ¨AndroidWorldä¸Šæå‡5.4%  
> å¤šæ¨¡æ€æ•°å­¦æ•°æ®æå‡AndroidWorldæ€§èƒ½6.3%

[2502] [InSTA: Towards Internet-Scale Training For Agents](https://arxiv.org/abs/2502.06776)
> è‡ªåŠ¨åŒ–ä¸‰çº§æ•°æ®æµæ°´çº¿: LLMä»»åŠ¡ç”Ÿæˆå™¨ã€LLMè½¨è¿¹ç”Ÿæˆå™¨â€‹ã€LLMè½¨è¿¹è¿‡æ»¤å™¨  
> åŸºäºæµè§ˆå™¨æ²™ç›’å®ä¾‹â€‹ç”Ÿäº§çœŸå®çš„æ•°æ®


[2412] [Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction](https://aguvis-project.github.io)
> stage-1: åŸºç¡€å®šä½æ•°æ®ï¼ˆ103.6ä¸‡æ¡ï¼‰  
> stage-2: è§„åˆ’æ¨ç†è½¨è¿¹æ•°æ®ï¼ˆ3.5ä¸‡æ¡ï¼‰ï¼Œæµè§ˆå™¨6,253ï¼Œç§»åŠ¨ç«¯27,647  
> è½¨è¿¹æ•°æ®ç”±GPT-4oç”Ÿæˆæ€è€ƒé“¾ä¸‰å…ƒç»„(obs, reason, action)

[2412] [ICLR2025] [AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials](https://agenttrek.github.io)
> çˆ¬äº†1880wæ•™ç¨‹ï¼ŒLLMç­›é€‰å‡º23wï¼Œæ•™ç¨‹å–‚ç»™VLMå–æ‰§è¡Œä»»åŠ¡ï¼Œè·å¾—1wè½¨è¿¹
> hfæ•°æ®é›†åº”è¯¥æ˜¯å¯ç”¨çš„ï¼Œè™½ç„¶hfçš„å¯è§†åŒ–å±•ç¤ºæ˜¯å•è½®çš„ï¼Œä½†è®ºæ–‡æåˆ°è½¨è¿¹æ˜¯å¤šè½®çš„ï¼Œä½†ä»¥å•è½®çš„æ ¼å¼å­˜å‚¨

### 3.3 Mobile


## 4. Reward Model
[2505][ZeroGUI: Automating Online GUI Learning at Zero Human Cost](https://arxiv.org/pdf/2505.23762)
> task verifierç”¨qwen2.5vl-32b

ğŸŒŸ [2505] [UI-Genie: A Self-Improving Approach for Iteratively Boosting MLLM-based Mobile GUI Agents](https://arxiv.org/pdf/2505.21496)
> å¤šç²’åº¦å¥–åŠ±æ¨¡å‹â€‹ï¼šåŒæ—¶æ”¯æŒstep-levelå’Œoutcome-levelè¯„ä¼°
> æ ¸å¿ƒè¦ç‚¹åœ¨äºå¦‚ä½•æåˆ°æ•°æ®æ¥è®­ç»ƒreward model

[2504] [AgentRewardBench: Evaluating Automatic Evaluations of Web Agent Trajectories](https://arxiv.org/abs/2504.08942)
> åœ¨ä¸åŒæµè§ˆå™¨benchmarkWebArena/VisualWebArena/AssistantBench/WorkArena/WorkArena++ä¸Šæ¨äº†GPT-4o/Claude 3.7S/Qwen2.5-VL/Llama 3.3çš„è½¨è¿¹1392æ¡ï¼Œäººå·¥ç²¾å¿ƒæ ‡æ³¨ä»»åŠ¡æˆåŠŸã€å‰¯ä½œç”¨ã€é‡å¤è¡Œä¸º  
> åŸºäºè¿™äº›GTï¼Œåˆ†æç°æœ‰benchmarkçš„è¯„ä¼°çš„å‡†ç¡®ç‡ï¼Œæ­ç¤ºè§„åˆ™è¯„ä¼°çš„ä¸¥é‡ç¼ºé™·ï¼Œå’ŒLLMè¯„ä¼°çš„ç“¶é¢ˆ  
> æå‡ºæ–°å‹ç®€åŒ–è¯„ä¼°æ¡†æ¶ï¼Œå°±æ˜¯æ”¹äº†prompt

## 5. Training Algorithm
[2504] [UI-TARS-1.5](https://seed-tars.com/1.5/)
> çº¯ç§€è‚Œè‚‰ï¼Œæ²¡æœ‰æŠ«éœ²æ›´å¤šç»†èŠ‚ï¼Œåªæåˆ°äº†â€œUI-TARS-1.5 integrates advanced reasoning enabled by reinforcement learningâ€  
> osworldä¸Šåˆ†æ•°42.5ï¼Œ7bçš„åˆ™æ˜¯28


## 6. Others
### x.1 General Agent
[2507] [Kimi K2: Open Agentic Intelligence](https://moonshotai.github.io/Kimi-K2/)

[2507] [GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning](https://arxiv.org/pdf/2507.01006)
> osworldä¸Šåˆ†æ•°ä¸å¤ªå¥½åªæœ‰14.7ï¼Œä½†å¯èƒ½æ˜¯æ²¡æœ‰ä¸“é¡¹å¾®è°ƒçš„åŸå› ï¼Œæ½œåŠ›åº”è¯¥æŒºå¤§

### x.2 Coding
[Qwen3-Coder: Agentic Coding in the World](https://qwenlm.github.io/blog/qwen3-coder/)

### x.3 Math


### x.4 Benchmark
ğŸŒŸ [2507] [Establishing Best Practices for Building Rigorous
Agentic Benchmarks](https://arxiv.org/pdf/2507.02825)
> æŒ‡å‡ºäº†ç°æœ‰agent benchmarkçš„é—®é¢˜ï¼Œä¾‹å¦‚webarenaå°±æœ‰é—®é¢˜  
> æå‡ºäº†ABCæ£€æŸ¥è¡¨ï¼Œä½œä¸ºæ£€æŸ¥ã€æ„å»ºagent benchmarkçš„åŸåˆ™  
> ä½œä¸ºä¸€ç§meta-researchï¼Œæ¯”è¾ƒæœ‰å¯å‘æ€§

[2507] [Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents](https://arxiv.org/pdf/2507.05495)
> é’ˆå¯¹deep researchçš„arenaï¼Œäº®ç‚¹æ˜¯é™¤äº†æœ€ç»ˆç»“æœï¼Œè¿˜å¯ä»¥å¯¹ä¸­é—´æ­¥éª¤ç‚¹èµ

[2501] [ACEBench: Who Wins the Match Point in Tool Usage?](https://arxiv.org/pdf/2501.12851)